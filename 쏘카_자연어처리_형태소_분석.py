# -*- coding: utf-8 -*-
"""쏘카 자연어처리 - 형태소 분석

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wktN1dwRuMBijfkDs6R9UofC-YqsKlhf
"""

!apt-get update 
!apt-get install g++ openjdk-8-jdk python-dev python3-dev 
!pip3 install JPype1-py3 
!pip3 install konlpy

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
df = pd.read_csv('/content/drive/MyDrive/2-2._lesion_info_table.csv', encoding='cp949')
print(df)

# level 순서: lesion_main_type -> lesion_sub_type -> lesion_detail_type

category = df.loc[:,['lesion_main_type', 'lesion_sub_type', 'lesion_detail_type','inspect_type', 'memo', 'description']]
category.dropna(axis=0)
category

# 3차 level의 종류
inspect_type=category['lesion_detail_type']
set(inspect_type.values.tolist())

# lesion_detail_type 그룹별 데이터 확인
groupdf=df.groupby('lesion_detail_type').get_group('위생_구토')
groupdf.head()

#형태소 분석 및 빈도수 계산 
from collections import Counter 
from konlpy.tag import Okt
okt = Okt()
def morph_and_stopword(s):
  token_ls = []
  tmp = okt.morphs(s, stem=True)
  for token in tmp:   #불용어 처리
    if len(token) > 1:
      token_ls.append(token)
  return token_ls

# 특수문자 제거
import re
def sub_special(s):
  return re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣0-9a-zA-Z ]','',s)

# memo, description 칼럼 데이터를 리스트에
memo=str(set(groupdf['memo'].values.tolist()))
memo=sub_special(memo)
memo=morph_and_stopword(memo)
memo=Counter(memo)
memo_rank=memo.most_common(100)

description=str(set(groupdf['description'].values.tolist())) 
description=sub_special(description)
description=morph_and_stopword(description)
description=Counter(description)
description_rank=description.most_common(100)

print(memo_rank)
print(description_rank)
# 형태소 분리
#print('memo:\n', morph_and_stopword(memo))
#print('description:\n', morph_and_stopword(description))